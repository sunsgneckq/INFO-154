{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Lab4",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "GTO2KMti07__",
        "8rXFXSh11BNk",
        "YAnuY8Sv1DoO",
        "ZlDfGvy61EMS",
        "1foS74O01FfP",
        "2rFY8D4Q1GsZ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Oyb_RNpFreOr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 4: SVM + Neural Networks #\n"
      ]
    },
    {
      "metadata": {
        "id": "yj9Uh79ereOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6SRFrhfreOt",
        "colab_type": "code",
        "outputId": "2056b72e-09a5-4572-e9da-ee8d8da7dee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://people.ischool.berkeley.edu/~zp/course_datasets/lab_4_training.csv\n",
        "!wget http://people.ischool.berkeley.edu/~zp/course_datasets/lab_4_test.csv\n",
        "\n",
        "df_train = pd.read_csv('./lab_4_training.csv')\n",
        "df_test = pd.read_csv('./lab_4_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 20:32:41--  http://people.ischool.berkeley.edu/~zp/course_datasets/lab_4_training.csv\n",
            "Resolving people.ischool.berkeley.edu (people.ischool.berkeley.edu)... 128.32.78.16\n",
            "Connecting to people.ischool.berkeley.edu (people.ischool.berkeley.edu)|128.32.78.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 105581 (103K) [text/csv]\n",
            "Saving to: ‘lab_4_training.csv.2’\n",
            "\n",
            "\rlab_4_training.csv.   0%[                    ]       0  --.-KB/s               \rlab_4_training.csv. 100%[===================>] 103.11K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-02-28 20:32:41 (1.56 MB/s) - ‘lab_4_training.csv.2’ saved [105581/105581]\n",
            "\n",
            "--2019-02-28 20:32:42--  http://people.ischool.berkeley.edu/~zp/course_datasets/lab_4_test.csv\n",
            "Resolving people.ischool.berkeley.edu (people.ischool.berkeley.edu)... 128.32.78.16\n",
            "Connecting to people.ischool.berkeley.edu (people.ischool.berkeley.edu)|128.32.78.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26523 (26K) [text/csv]\n",
            "Saving to: ‘lab_4_test.csv.2’\n",
            "\n",
            "lab_4_test.csv.2    100%[===================>]  25.90K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-02-28 20:32:42 (1.21 MB/s) - ‘lab_4_test.csv.2’ saved [26523/26523]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>year</th>\n",
              "      <th>eyecolor</th>\n",
              "      <th>height</th>\n",
              "      <th>miles</th>\n",
              "      <th>brothers</th>\n",
              "      <th>sisters</th>\n",
              "      <th>computertime</th>\n",
              "      <th>exercise</th>\n",
              "      <th>exercisehours</th>\n",
              "      <th>musiccds</th>\n",
              "      <th>playgames</th>\n",
              "      <th>watchtv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1303</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>second</td>\n",
              "      <td>green</td>\n",
              "      <td>73.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>other</td>\n",
              "      <td>71.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>489</td>\n",
              "      <td>male</td>\n",
              "      <td>22</td>\n",
              "      <td>fourth</td>\n",
              "      <td>hazel</td>\n",
              "      <td>75.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1415</td>\n",
              "      <td>male</td>\n",
              "      <td>19</td>\n",
              "      <td>second</td>\n",
              "      <td>brown</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>616</td>\n",
              "      <td>male</td>\n",
              "      <td>22</td>\n",
              "      <td>fourth</td>\n",
              "      <td>hazel</td>\n",
              "      <td>71.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 gender  age    year eyecolor  height  miles  brothers  sisters  \\\n",
              "0        1303   male   20  second    green    73.0  210.0         0        1   \n",
              "1          36   male   20   third    other    71.0   90.0         1        0   \n",
              "2         489   male   22  fourth    hazel    75.0  200.0         0        1   \n",
              "3        1415   male   19  second    brown    72.0   35.0         2        2   \n",
              "4         616   male   22  fourth    hazel    71.0   15.0         2        1   \n",
              "\n",
              "   computertime exercise  exercisehours  musiccds  playgames  watchtv  \n",
              "0          10.0      Yes            5.0      50.0        1.0     15.0  \n",
              "1          15.0      Yes            4.0      10.0        0.0      1.0  \n",
              "2           1.0      Yes            2.0     150.0        1.0     10.0  \n",
              "3          20.0      Yes            5.0     100.0        0.0      7.0  \n",
              "4          10.0      Yes            7.0      10.0        0.0      5.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "RGt_10ZAreOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 1###\n",
        "Calculate a baseline accuracy measure using the majority class, assuming a target variable of 'gender'. The majority class is the most common value of the target variable in a particular dataset. Accuracy is calculated as (true positives + true negatives) / (all negatives and positives)"
      ]
    },
    {
      "metadata": {
        "id": "UZPiLgekreOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Question 1.a**  \n",
        "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
      ]
    },
    {
      "metadata": {
        "id": "iYjEFc1greOx",
        "colab_type": "code",
        "outputId": "a4042052-5b6a-4ec5-8706-ba7cac120669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "df_train.groupby(\"gender\").size()\n",
        "tn, fp, fn, tp = confusion_matrix(df_train[\"gender\"].tolist(),[\"female\" for i in np.arange(1590)], labels=[\"female\", \"male\"]).ravel()\n",
        "tn, fp, fn, tp\n",
        "855.0/(855.0+735.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5377358490566038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "id": "RtvFM-hM0y2o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The majority class is the female, if we always predicted this class in the training set, we will get an accuracy of 0.5377358490566038"
      ]
    },
    {
      "metadata": {
        "id": "ULPKW0IvreOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 1.b**   \n",
        "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dfU5mwh405vq",
        "outputId": "26b675c7-ce06-4806-9db6-ab5c73bf88fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "df_test.groupby(\"gender\").size()\n",
        "208.0/(208.0+190.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5226130653266332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pINRUJxG05v4"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: In the test set, we will get accuracy of 0.5226130653266332"
      ]
    },
    {
      "metadata": {
        "id": "GKb2Ju-GreO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 2 ###\n",
        "Get started with Neural Networks."
      ]
    },
    {
      "metadata": {
        "id": "UYI6e3F3reO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "   \n",
        "Choose a NN implementation (eg: scikit-learn) and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
        "\n",
        "NOTE: When possible, specify the logsig (sigmoid/logistc) function as the transfer function (another word for activation function) for the output node and use Levenberg-Marquardt backpropagation (lbfgs). It is possible to specify logsig or logistic in Sklearn MLPclassifier (Neural net).  "
      ]
    },
    {
      "metadata": {
        "id": "4am3sGc4reO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.a**   \n",
        "Train a neural network with a single 10 node hidden layer. Only use the Height feature of the dataset to predict the Gender. You will have to change Gender to a 0 and 1 class. After training, use your trained model to predict the class using the height feature from the training set. What was the accuracy of this prediction?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jbAzltaw067l",
        "outputId": "f203c652-f108-4bd0-d861-8f64b5ec422a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer #to turn categorial variables into numeric arrays\n",
        "from sklearn import preprocessing #to transform the feature labels\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "df_train\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "gender.transform(df_train[\"gender\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = df_train[\"height\"].reshape(-1, 1) \n",
        "y = df_train[\"gender_trans\"]\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(X,y)\n",
        "clf.predict(df_train[\"height\"].reshape(-1, 1) )\n",
        "clf.score(df_train[\"height\"].reshape(-1, 1),df_train[\"gender_trans\"])\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8465408805031447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EuaCk0l0067q"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: Accuracy: 0.8465408805031447"
      ]
    },
    {
      "metadata": {
        "id": "AkqzIeshreO2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.b**  \n",
        "Take the trained model from question 2.b and use it to predict the test set. This can be accomplished by taking the trained model and giving it the Height feature values from the test set. What is the accuracy of this model on the test set?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tw25ezWp07hj",
        "outputId": "e5b95728-aded-4526-917b-53ff644a7d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "gender.transform(df_test[\"gender\"])\n",
        "df_test[\"gender_trans\"]=gender.transform(df_test[\"gender\"])\n",
        "clf.predict(df_test[\"height\"].reshape(-1, 1) )\n",
        "clf.score(df_test[\"height\"].reshape(-1, 1),df_test[\"gender_trans\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HbHMAFvw07hm"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The  accuracy of the test set is 0.8542713567839196"
      ]
    },
    {
      "metadata": {
        "id": "uMmIfsNEreO3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.c**   \n",
        "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the height feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.c with the log version and the normalized and centered version of this feature"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wDhCZPaU07_8",
        "outputId": "165a9fb5-c22f-466c-b891-45547a192438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "#Log\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        "df_test[\"gender_trans\"]=gender.transform(df_test[\"gender\"])\n",
        " \n",
        "  \n",
        "clf.fit(np.log(df_train[\"height\"].reshape(-1, 1)), df_train[\"gender_trans\"])\n",
        "\n",
        "print(clf.score(np.log(df_train[\"height\"].reshape(-1, 1)),df_train[\"gender_trans\"]))\n",
        "print(clf.score(np.log(df_test[\"height\"].reshape(-1, 1)),df_test[\"gender_trans\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8465408805031447\n",
            "0.8542713567839196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0fVfVpsOWR7k",
        "colab_type": "code",
        "outputId": "029eb7fa-e250-44ac-94d9-57af54eb0618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#standard normalization \n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(df_train[\"height\"].reshape(-1, 1))\n",
        "X = scaler.transform(df_train[\"height\"].reshape(-1, 1))\n",
        "y = df_train[\"gender_trans\"]\n",
        "\n",
        "T = preprocessing.MinMaxScaler()\n",
        "T.fit(X,y)\n",
        "X2=T.transform(X)\n",
        "\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(X2,y)\n",
        "\n",
        "print(clf.score(X2, df_train[\"gender_trans\"]))\n",
        "print(clf.score(T.transform(scaler.transform(df_test[\"height\"].reshape(-1, 1))),df_test[\"gender_trans\"]))\n",
        "#train_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8465408805031447\n",
            "0.8542713567839196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GTO2KMti07__"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: Both the log transformation and normalization gives the training data has accuracy of 0.8465408805031447 and the log transformation of test data has accuracy of 0.8542713567839196. "
      ]
    },
    {
      "metadata": {
        "id": "2_SlOdcarePC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Question 3###\n",
        "The rest of features in this dataset barring a few are categorical. Neither ML method accepts categorical features, so transform year, eyecolor, exercise into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these binary variable transformed features, train and predict the class of the test set."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YjhzBFNV1Aip",
        "outputId": "69c2b603-96b0-470f-eb21-d4377c86aa51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "# df_train[\"gender\"]=df_train[\"gender_trans\"]\n",
        "# df_train[\"eyecolor\"].unique()\n",
        "\n",
        "\n",
        "\n",
        "# df_train[\"exercise\"].unique()\n",
        "\n",
        "\n",
        "\n",
        "# eyecolors = preprocessing.LabelEncoder()\n",
        "# eyecolors.fit(['green', 'other', 'hazel', 'brown', 'blue'])\n",
        "# #df_train[\"eyecolor\"]=eyecolors.transform(df_train[\"eyecolor\"])\n",
        "# year = preprocessing.LabelEncoder()\n",
        "# year.fit(['second', 'third', 'fourth', 'other', 'first', 'first\"'])\n",
        "# #df_train[\"year\"]=year.transform(df_train[\"year\"])\n",
        "# exercise=preprocessing.LabelEncoder()\n",
        "# df_train[\"exercise\"].unique()\n",
        "# exercise.fit(['Yes', 'No'])\n",
        "# df_train[\"exercise\"]=exercise.transform(df_train[\"exercise\"])\n",
        "# df_train\n",
        " \n",
        "pd.concat([pd.get_dummies(df_train[\"eyecolor\"]), pd.get_dummies(df_train[\"year\"]),pd.get_dummies(df_train[\"exercise\"])], axis=1)\n",
        "pd.concat([pd.get_dummies(df_test[\"eyecolor\"]), pd.get_dummies(df_test[\"year\"]),pd.get_dummies(df_test[\"exercise\"])], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blue</th>\n",
              "      <th>brown</th>\n",
              "      <th>green</th>\n",
              "      <th>hazel</th>\n",
              "      <th>other</th>\n",
              "      <th>first</th>\n",
              "      <th>first\"</th>\n",
              "      <th>fourth</th>\n",
              "      <th>other</th>\n",
              "      <th>second</th>\n",
              "      <th>third</th>\n",
              "      <th>No</th>\n",
              "      <th>Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     blue  brown  green  hazel  other  first  first\"  fourth  other  second  \\\n",
              "0       0      0      1      0      0      0       0       0      0       1   \n",
              "1       0      0      0      0      1      0       0       0      0       0   \n",
              "2       0      0      0      1      0      0       0       1      0       0   \n",
              "3       0      1      0      0      0      0       0       0      0       1   \n",
              "4       0      0      0      1      0      0       0       1      0       0   \n",
              "5       1      0      0      0      0      0       0       0      0       1   \n",
              "6       0      0      1      0      0      0       0       0      0       1   \n",
              "7       0      1      0      0      0      0       0       0      0       0   \n",
              "8       0      0      0      1      0      0       0       0      0       1   \n",
              "9       0      1      0      0      0      0       0       0      0       1   \n",
              "10      1      0      0      0      0      0       0       0      1       0   \n",
              "11      1      0      0      0      0      0       0       0      0       1   \n",
              "12      0      1      0      0      0      0       0       0      0       0   \n",
              "13      0      0      1      0      0      0       0       1      0       0   \n",
              "14      0      1      0      0      0      0       0       0      0       1   \n",
              "15      1      0      0      0      0      0       0       0      0       0   \n",
              "16      1      0      0      0      0      0       0       1      0       0   \n",
              "17      0      0      0      1      0      0       0       0      0       1   \n",
              "18      0      0      0      1      0      0       0       1      0       0   \n",
              "19      1      0      0      0      0      0       0       0      1       0   \n",
              "20      0      1      0      0      0      1       0       0      0       0   \n",
              "21      0      0      1      0      0      0       0       0      0       0   \n",
              "22      0      1      0      0      0      0       0       0      0       0   \n",
              "23      1      0      0      0      0      0       0       0      0       1   \n",
              "24      1      0      0      0      0      0       0       0      0       1   \n",
              "25      0      0      0      1      0      1       0       0      0       0   \n",
              "26      0      0      1      0      0      0       0       0      0       1   \n",
              "27      1      0      0      0      0      0       0       1      0       0   \n",
              "28      0      1      0      0      0      1       0       0      0       0   \n",
              "29      1      0      0      0      0      0       0       0      0       0   \n",
              "..    ...    ...    ...    ...    ...    ...     ...     ...    ...     ...   \n",
              "368     0      1      0      0      0      0       0       1      0       0   \n",
              "369     0      1      0      0      0      0       0       1      0       0   \n",
              "370     0      1      0      0      0      0       0       0      0       0   \n",
              "371     0      1      0      0      0      0       0       0      0       1   \n",
              "372     0      1      0      0      0      0       0       0      0       0   \n",
              "373     1      0      0      0      0      0       0       1      0       0   \n",
              "374     1      0      0      0      0      0       0       0      0       1   \n",
              "375     0      0      0      1      0      1       0       0      0       0   \n",
              "376     0      0      1      0      0      0       0       0      0       1   \n",
              "377     1      0      0      0      0      0       0       1      0       0   \n",
              "378     1      0      0      0      0      0       0       0      0       0   \n",
              "379     0      0      1      0      0      0       0       0      0       1   \n",
              "380     1      0      0      0      0      0       0       0      0       1   \n",
              "381     0      0      1      0      0      1       0       0      0       0   \n",
              "382     1      0      0      0      0      0       0       0      0       1   \n",
              "383     0      1      0      0      0      0       0       1      0       0   \n",
              "384     0      1      0      0      0      1       0       0      0       0   \n",
              "385     1      0      0      0      0      0       0       0      1       0   \n",
              "386     1      0      0      0      0      1       0       0      0       0   \n",
              "387     0      1      0      0      0      1       0       0      0       0   \n",
              "388     1      0      0      0      0      0       0       0      0       0   \n",
              "389     0      0      0      1      0      0       0       0      0       0   \n",
              "390     0      1      0      0      0      0       0       0      0       0   \n",
              "391     1      0      0      0      0      0       0       0      0       0   \n",
              "392     0      1      0      0      0      0       0       1      0       0   \n",
              "393     1      0      0      0      0      0       0       0      0       1   \n",
              "394     0      1      0      0      0      0       0       0      0       0   \n",
              "395     0      1      0      0      0      0       0       0      0       1   \n",
              "396     0      1      0      0      0      0       0       0      0       1   \n",
              "397     0      0      1      0      0      0       0       0      0       0   \n",
              "\n",
              "     third  No  Yes  \n",
              "0        0   0    1  \n",
              "1        1   0    1  \n",
              "2        0   0    1  \n",
              "3        0   0    1  \n",
              "4        0   0    1  \n",
              "5        0   0    1  \n",
              "6        0   0    1  \n",
              "7        1   1    0  \n",
              "8        0   0    1  \n",
              "9        0   0    1  \n",
              "10       0   1    0  \n",
              "11       0   1    0  \n",
              "12       1   0    1  \n",
              "13       0   0    1  \n",
              "14       0   0    1  \n",
              "15       1   0    1  \n",
              "16       0   0    1  \n",
              "17       0   1    0  \n",
              "18       0   0    1  \n",
              "19       0   1    0  \n",
              "20       0   0    1  \n",
              "21       1   0    1  \n",
              "22       1   1    0  \n",
              "23       0   1    0  \n",
              "24       0   0    1  \n",
              "25       0   0    1  \n",
              "26       0   0    1  \n",
              "27       0   0    1  \n",
              "28       0   0    1  \n",
              "29       1   1    0  \n",
              "..     ...  ..  ...  \n",
              "368      0   0    1  \n",
              "369      0   1    0  \n",
              "370      1   1    0  \n",
              "371      0   0    1  \n",
              "372      1   0    1  \n",
              "373      0   0    1  \n",
              "374      0   0    1  \n",
              "375      0   1    0  \n",
              "376      0   0    1  \n",
              "377      0   0    1  \n",
              "378      1   0    1  \n",
              "379      0   1    0  \n",
              "380      0   1    0  \n",
              "381      0   0    1  \n",
              "382      0   0    1  \n",
              "383      0   1    0  \n",
              "384      0   0    1  \n",
              "385      0   1    0  \n",
              "386      0   1    0  \n",
              "387      0   1    0  \n",
              "388      1   0    1  \n",
              "389      1   0    1  \n",
              "390      1   0    1  \n",
              "391      1   0    1  \n",
              "392      0   0    1  \n",
              "393      0   0    1  \n",
              "394      1   1    0  \n",
              "395      0   0    1  \n",
              "396      0   1    0  \n",
              "397      1   1    0  \n",
              "\n",
              "[398 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "_jGlnavorePE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 3.a**    \n",
        "What was your accuracy using Neural Network with a single 10 node hidden layer? During training, use a maximum number of iterations of 50. (Expected training time: ~15 mins)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4qQh3NFi1BNi",
        "outputId": "461fa6ca-5b02-42e3-b295-18375bc8ba09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\", max_iter=50)\n",
        "feature=pd.concat([pd.get_dummies(df_train[\"eyecolor\"]), pd.get_dummies(df_train[\"year\"]),pd.get_dummies(df_train[\"exercise\"])], axis=1)\n",
        "\n",
        "clf.fit(feature,df_train[\"gender_trans\"])\n",
        "print(clf.score(feature,df_train[\"gender_trans\"]))\n",
        "\n",
        " \n",
        "gender.transform(df_test[\"gender\"])\n",
        "df_test[\"gender_trans\"]=gender.transform(df_test[\"gender\"])\n",
        "print(clf.score(pd.concat([pd.get_dummies(df_test[\"eyecolor\"]), pd.get_dummies(df_test[\"year\"]),pd.get_dummies(df_test[\"exercise\"])], axis=1),df_test[\"gender_trans\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5691823899371069\n",
            "0.6105527638190955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8rXFXSh11BNk"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: Training data set has accuracy of 0.5691823899371069 and test data set has accuracy 0.6105527638190955"
      ]
    },
    {
      "metadata": {
        "id": "dSSr9sBlrePG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 4###\n",
        "Using a NN, report the accuracy on  the test set of a model that trained only on the height and the eye color features of instances in the training set."
      ]
    },
    {
      "metadata": {
        "id": "rMNSlOmJrePG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 4.a**  \n",
        "What is the accuracy on the test set using the original height values (no pre-processing) and eye color as a one-hot?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F_vN4tyv1Ckq",
        "outputId": "84a6ab9c-d9bc-4fc7-ef09-6bdc08fde70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "eyecolors = preprocessing.LabelEncoder()\n",
        "eyecolors.fit(['green', 'other', 'hazel', 'brown', 'blue'])\n",
        "df_train[\"eyecolor\"]=eyecolors.transform(df_train[\"eyecolor\"])\n",
        "df_test[\"eyecolor\"]=eyecolors.transform(df_test[\"eyecolor\"])\n",
        "\n",
        "\n",
        "\n",
        "df_train[[\"height\",\"eyecolor\"]]\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(df_train[[\"height\",\"eyecolor\"]],df_train[\"gender_trans\"])\n",
        "clf.score(df_test[[\"height\",\"eyecolor\"]],df_test[\"gender_trans\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CaL2o0TW1Cks"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: Accuracy on test data 0.8542713567839196"
      ]
    },
    {
      "metadata": {
        "id": "NC8Ipx9QrePH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 4.b**  \n",
        "What is the accuracy on the test set using the log of height values (applied to both training and testing sets) and eye color as a one-hot?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cFvzNv6O1DG3",
        "outputId": "d726e900-7b52-43f9-84b5-8237a166024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "p=df_train[[\"eyecolor\",\"height\"]]\n",
        "p[\"height\"]=np.log(p[\"height\"])\n",
        "q=df_test[[\"eyecolor\",\"height\"]]\n",
        "q[\"height\"]=np.log(q[\"height\"])\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(p,df_train[\"gender_trans\"])\n",
        "clf.score(q,df_test[\"gender_trans\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8592964824120602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pt3NMp1M1DG4"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The test accuracy is 0.8592964824120602"
      ]
    },
    {
      "metadata": {
        "id": "iYm2jqnprePI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 4.c**  \n",
        "What is the accuracy on the test set using the Z-score of height values and eye color as a one-hot? \n",
        "\n",
        "Z-score is a normalization function. It is the value of a feature minus the average value for that feature (in the training set), divided by the standard deviation of that feature (in the training set). Remember that, whenever applying a function to a feature in the training set, it also has to be applied to that same feature in the test set."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P3mDjF6N1DoN",
        "outputId": "5a172af2-a429-4b16-d1bd-edcd015caebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(df_train[\"height\"].reshape(-1, 1))\n",
        "X = scaler.transform(df_train[\"height\"].reshape(-1, 1))\n",
        "zscore=df_train[[\"eyecolor\"]]\n",
        "zscore[\"z\"]=X\n",
        "zscore2=df_test[[\"eyecolor\"]]\n",
        "zscore2[\"z\"]=scaler.transform(df_test[\"height\"].reshape(-1, 1))\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(zscore,df_train[\"gender_trans\"])\n",
        "clf.score(zscore2,df_test[\"gender_trans\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8693467336683417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YAnuY8Sv1DoO"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The test set has accuracy of 0.8693467336683417"
      ]
    },
    {
      "metadata": {
        "id": "Fh9qwu_9rePJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 5 ###\n",
        "Repeat question 5 for exercise hours + eye color"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JAgHz_r-1EMR",
        "outputId": "493536a0-a454-439a-cafe-6cdb64009619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "#Repeat 4a\n",
        " \n",
        "df_train[[\"exercisehours\",\"eyecolor\"]]\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(df_train[[\"exercisehours\",\"eyecolor\"]],df_train[\"gender_trans\"])\n",
        "print(clf.score(df_test[[\"exercisehours\",\"eyecolor\"]],df_test[\"gender_trans\"]))\n",
        " \n",
        " #repeat 4b\n",
        "\n",
        "p=df_train[[\"eyecolor\",\"exercisehours\"]]\n",
        "p=p[p['exercisehours']!=0.0]\n",
        "p[\"exercisehours\"]=np.log(p[\"exercisehours\"])\n",
        "\n",
        "q=df_test[[\"eyecolor\",\"exercisehours\"]]\n",
        "q=q[q['exercisehours']!=0.0]\n",
        "q[\"exercisehours\"]=np.log(q[\"exercisehours\"])\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(p,df_train[df_train['exercisehours']!=0.0][\"gender_trans\"])\n",
        "print(clf.score(q,df_test[df_train['exercisehours']!=0.0][\"gender_trans\"]))\n",
        "\n",
        "#repeat 4c\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(df_train[\"exercisehours\"].reshape(-1, 1))\n",
        "X = scaler.transform(df_train[\"exercisehours\"].reshape(-1, 1))\n",
        "zscore=df_train[[\"eyecolor\"]]\n",
        "zscore[\"z\"]=X\n",
        "zscore2=df_test[[\"eyecolor\"]]\n",
        "zscore2[\"z\"]=scaler.transform(df_test[\"exercisehours\"].reshape(-1, 1))\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=1,activation=\"logistic\")\n",
        "clf.fit(zscore,df_train[\"gender_trans\"])\n",
        "print(clf.score(zscore2,df_test[\"gender_trans\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5728643216080402\n",
            "0.606694560669456\n",
            "0.5628140703517588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZlDfGvy61EMS"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: \n",
        "Test sets accuracy is \n",
        "\n",
        "0.5728643216080402\n",
        "\n",
        "0.606694560669456\n",
        "\n",
        "0.5628140703517588"
      ]
    },
    {
      "metadata": {
        "id": "JYVuaPWgrePL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 6###\n",
        "Combine the features from question 4, 5, and exercise hours from question 6 (using the best normalization feature set form questions 5 and 6)"
      ]
    },
    {
      "metadata": {
        "id": "1iAiFhlFrePM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 6.a**  \n",
        "What was the NN accuracy on the test set using the single 10 node hidden layer?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QuLJ6sTB1FfN",
        "outputId": "a1a288da-c40a-450b-d7fc-61098b20f2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "#Height, eyecolor, exercise hours\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "Q6=df_train[df_train['exercisehours']!=0.0]\n",
        "Q6[\"gender_trans\"]=gender.transform(Q6[\"gender\"])\n",
        "a=Q6[[\"eyecolor\",\"exercisehours\",\"height\",\"gender_trans\"]]\n",
        "\n",
        "a[\"height\"]=np.log(a[\"height\"])\n",
        "a[\"exercisehours\"]=np.log(a[\"exercisehours\"])\n",
        " \n",
        "Q7=df_test[df_test['exercisehours']!=0.0]\n",
        "b=Q7[[\"eyecolor\",\"exercisehours\",\"height\"]]\n",
        "b[\"height\"]=np.log(b[\"height\"])\n",
        "b[\"exercisehours\"]=np.log(b[\"exercisehours\"])\n",
        "\n",
        "b[\"gender_trans\"]=gender.transform(Q7[\"gender\"])\n",
        "\n",
        "\n",
        " \n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10), random_state=233,activation=\"logistic\")\n",
        "clf.fit(a[[\"eyecolor\",\"exercisehours\",\"height\"]],a[\"gender_trans\"])\n",
        "print(clf.score(b[[\"eyecolor\",\"exercisehours\",\"height\"]], b[\"gender_trans\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8451882845188284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1foS74O01FfP"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The accuracy of the test data is 0.8451882845188284"
      ]
    },
    {
      "metadata": {
        "id": "Jusc-kofrePP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 7- Bonus (10%)###\n",
        "Can you improve your test set prediction accuracy by 5% or more?  \n",
        "\n",
        "See how close to that milestone of improvement you can get by modifying the tuning parameters of  Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate aka mu). A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. \n",
        "\n",
        "While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies to generally to any ML technique with tuning parameters.\n",
        "\n",
        "Please also write a paragraph in a markdown cell below with an explanation of your approach and evaluation metrics.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qvpoUdeq1GsX",
        "outputId": "3a9bf734-60d0-43e6-fcf7-b6c4789798ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# # YOUR CODE HERE\n",
        "# clf = (solver='lbfgs', alpha=1e-5, hidden_layer_sizes=10, random_state=10,activation=\"logistic\")\n",
        "# clf.fit(a[[\"height\",\"eyecolor\",\"exercisehours\"]],a[\"genders\"])\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform as sp_rand\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def svc_param_selection(X, y, nfolds):\n",
        "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
        "    gammas = [0.001, 0.01, 0.1, 1,3]\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
        "    grid_search.fit(X, y)\n",
        "    grid_search.best_params_\n",
        "    return grid_search.best_params_\n",
        "\n",
        "\n",
        "svc_param_selection(a,a[\"gender_trans\"],5)\n",
        "p=SVC(gamma=50, C=10000000,random_state=50)\n",
        "p.fit(a[[\"eyecolor\",\"exercisehours\",\"height\"]],a[\"gender_trans\"])\n",
        "a=p.score(a[[\"eyecolor\",\"exercisehours\",\"height\"]],a[\"gender_trans\"])\n",
        "print(a*100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.88877654196158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2rFY8D4Q1GsZ"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: I've tried a lot of method and approaches. I first try to use xgboost to find the best features that can predict the gender. Then I use GridSearchCV to find the best hyperparameter for the transformed features I had. I noticed that increasing in gamma which is the kernel coefficient and Penalty parameter would increase the accuracy of the prediction even though the run time would also increase. Since we are only using 3 features, it won't take too long and the prediciton accuracy is now 89.888% which increases by slightly more than 5%"
      ]
    },
    {
      "metadata": {
        "id": "3qUqBKicreO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Question 8 (Bonus: 20%) ###\n",
        "Get started with Support Vector Machines."
      ]
    },
    {
      "metadata": {
        "id": "pNYLaAhureO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "  \n",
        "Chose a SVM implementation and specify which you choose. Be sure the implementation allows you to choose between linear and RBF kernels."
      ]
    },
    {
      "metadata": {
        "id": "1hAV-qKdreO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.a**   \n",
        "Use the same dataset from 2.a using the linear kernel to find training set prediction accuracy."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m3XM3euo08oN",
        "outputId": "9c28267c-0dff-46f9-af5d-65b6d2c775c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = df_train[\"height\"].reshape(-1, 1) \n",
        "y = df_train[\"gender_trans\"]\n",
        "\n",
        "clf = SVC(10**(3), kernel = \"linear\")\n",
        "clf.fit(X, y)\n",
        "clf.score(df_train[\"height\"].reshape(-1, 1),df_train[\"gender_trans\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8465408805031447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KEqCSegT08oV"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: Accuracy for training set is 0.8465408805031447"
      ]
    },
    {
      "metadata": {
        "id": "96Fl7LQUreO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.b**   \n",
        "Use the same dataset from 2.a using the linear kernel to find test set prediction accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QgEJ14y209KT",
        "outputId": "58ecb7f8-f576-43a2-d3ca-c9c40f7e1f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "#df_test[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = df_test[\"height\"].reshape(-1, 1) \n",
        "y = df_test[\"gender_trans\"]\n",
        "\n",
        "clf.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ne9ORE8J09KY"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The accuracy of the test sets is 0.8542713567839196"
      ]
    },
    {
      "metadata": {
        "id": "XWNy8vVdreO8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.c**   \n",
        "Use the same dataset from 2.a using the RBF kernel  to find training set prediction accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e4_R8m1609v6",
        "outputId": "7f04d111-a763-4973-d8bb-14e614a13caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = df_train[\"height\"].reshape(-1, 1) \n",
        "y = df_train[\"gender_trans\"]\n",
        "\n",
        "clf = SVC(10**(3), kernel = \"rbf\")\n",
        "clf.fit(X, y)\n",
        "clf.score(df_train[\"height\"].reshape(-1, 1),df_train[\"gender_trans\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8465408805031447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zeao7-OV09wB"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The accuracy of the test data set is 0.8465408805031447"
      ]
    },
    {
      "metadata": {
        "id": "oeaE1JffreO-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.d**   \n",
        "Use the same dataset from 2.a using the RBF kernel  to find test set prediction accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S3IuICJm0-2E",
        "outputId": "1667ad5c-9085-43f9-97f3-8361a6ff60c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "#df_test[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = df_test[\"height\"].reshape(-1, 1) \n",
        "y = df_test[\"gender_trans\"]\n",
        "\n",
        "clf.score(X,y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_XL_S1vQ0-2L"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The accuracy of the test data is 0.8542713567839196"
      ]
    },
    {
      "metadata": {
        "id": "SuqdVvlrreO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.e**   \n",
        "Use the same dataset from 2.c (log) using the RBF to find test set prediction accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "USVRMcUT0_T3",
        "outputId": "17f441b8-5641-405e-c0a5-0fff89fd87ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "X = np.log(df_train[\"height\"].reshape(-1, 1) )\n",
        "y = df_train[\"gender_trans\"]\n",
        "\n",
        "clf = SVC( kernel = \"rbf\")\n",
        "clf.fit(X, y)\n",
        "\n",
        "X2 = np.log(df_test[\"height\"].reshape(-1, 1) )\n",
        "y2 = df_test[\"gender_trans\"]\n",
        "\n",
        "clf.score(X2,y2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wp8n_kUc0_T8"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The test set has accuracy of 0.8542713567839196"
      ]
    },
    {
      "metadata": {
        "id": "Oo9CZNDYrePB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8.f**   \n",
        "Z-score is a normalization technique. It is the value of a feature minus the average value for that feature in the training set, divided by the standard deviation of that feature in the training set. Repeat question 3.e using Z-score and note if there is any difference in accuracy and comment on why there is a change or no change in accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HGPofGGm0_tx",
        "outputId": "60b91dc3-996b-46f5-a85a-8e7610a94ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(df_train[\"height\"].reshape(-1, 1))\n",
        "X = scaler.transform(df_train[\"height\"].reshape(-1, 1))\n",
        "\n",
        "gender = preprocessing.LabelEncoder()\n",
        "gender.fit([\"male\",\"female\"])\n",
        "df_train[\"gender_trans\"]=gender.transform(df_train[\"gender\"])\n",
        " \n",
        "y = df_train[\"gender_trans\"]\n",
        "\n",
        "clf2 = SVC( kernel = \"rbf\")\n",
        "clf2.fit(X, y)\n",
        "\n",
        "X2 = scaler.transform(df_test[\"height\"].reshape(-1, 1))\n",
        "y2 = df_test[\"gender_trans\"]\n",
        "\n",
        "clf2.score(X2,y2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8542713567839196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Aw1fJ59W0_t3"
      },
      "cell_type": "markdown",
      "source": [
        "###ANSWER: The test has accuracy of 0.8542713567839196. They have the same prediction. Because SVM will nonlinearly maps samples into a higher dimensional space and can handle the relation between class that are nonlinear. This kernel nonlinearly maps samples into a higher dimensional space so it, unlike the linear kernel, can handle the case when the relation between class labels and attributes is nonlinear. Log transformation also map the data onto a different scale but they both don't change the distribution. Therefore, the  prediction remained the same.\n"
      ]
    }
  ]
}